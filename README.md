# ğŸ§  3D Brain Tumor Segmentation using 3D U-Net (BraTS 2021)
### **Deep Learning â€¢ Medical Imaging â€¢ PyTorch â€¢ End-to-End Research Pipeline**

<div align="center">
<img src="samples/multi_slice_segmentation_comparison.png" width="800">
</div>

---

## ğŸš€ Project Overview

This repository implements a **complete 3D brain tumor segmentation pipeline** using the **BraTS 2021** dataset and a fully custom **3D U-Net** designed and trained from scratch in PyTorch.

The project covers every step needed in a medical-grade pipeline:

âœ” NIfTI preprocessing  
âœ” Brain extraction through non-zero bounding box  
âœ” True 3D resampling to 1mmÂ³  
âœ” Four MRI modalities (FLAIR, T1, T1CE, T2)  
âœ” Intensity normalization  
âœ” Final shape: **128 Ã— 128 Ã— 128**  
âœ” 3D U-Net with skip connections  
âœ” Mixed Precision (AMP)  
âœ” Gradient Accumulation  
âœ” Dice + CrossEntropy hybrid loss  
âœ” Clean evaluation + visualizations  
âœ” Modular folder structure  

This work trains on **100 patients** due to Kaggle notebook storage limits â€” but maintains a *research-level* structure and design to scale to all **1251 patients**.

---

# ğŸ¯ Objective

Segment the 3 tumor regions defined in BraTS:

- **Whole Tumor (WT):** Labels 1 + 2 + 3  
- **Tumor Core (TC):** Labels 2 + 3  
- **Enhancing Tumor (ET):** Label 3  

---

# ğŸ“ Repository Structure



# ğŸ“ Repository Structure

brats-3d-unet/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ bbox.py
â”‚ â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”‚ â”œâ”€â”€ utils_io.py
â”‚ â”œâ”€â”€ model/
â”‚ â”‚ â”œâ”€â”€ Unet-3d.py
â”‚ â”‚ â”œâ”€â”€ losses.py
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ dataloader.py
â”‚ â”‚ â”œâ”€â”€ train_loop.py
â”‚ â”‚ â”œâ”€â”€ metrics.py
â”‚ â”œâ”€â”€ inference/
â”‚ â”‚ â”œâ”€â”€ predict.py
â”‚ â”‚ â”œâ”€â”€ visualization.py
â”‚ â”œâ”€â”€ evaluation/
â”‚ â”œâ”€â”€ eval_patient.py
â”‚
â”œâ”€â”€ samples/
â”‚ â”œâ”€â”€ comparison_grid.png
â”‚ â”œâ”€â”€ modalities.png
â”‚ â”œâ”€â”€ multi_slice_segmentation_comparison.png
â”‚ â”œâ”€â”€ multi_slice_segmentation_comparison2.png
â”‚ â”œâ”€â”€ overlay_groundtruth.png
â”‚ â”œâ”€â”€ overlay_prediction.png
â”‚ â””â”€â”€ overlay.png
â”‚
â”œâ”€â”€ saved_model/
â”‚ â””â”€â”€ model_chunk0.pth
â”‚
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ brats2021-3d-unet-pipeline.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

# âš™ï¸ Pipeline Details


---

# ğŸ”§ Preprocessing Pipeline (Fully Reproducible)

The preprocessing code (in `src/data/`) performs:

### **1ï¸âƒ£ Load all modalities using SimpleITK**
- FLAIR  
- T1  
- T1CE  
- T2  

### **2ï¸âƒ£ Brain cropping**
Bounding box is computed using non-zero voxels.

### **3ï¸âƒ£ True 3D resampling â†’ 1mmÂ³**
Using SimpleITK's `ResampleImageFilter`.

### **4ï¸âƒ£ Intensity normalization**
Normalize *only brain voxels* â†’ background stays 0.

### **5ï¸âƒ£ Resize to 128Ã—128Ã—128**
Using PyTorch trilinear interpolation.

### **6ï¸âƒ£ Label cleanup**
Remap label **4 â†’ 3** (BraTS convention).

---

# ğŸ“¸ Visualization Samples

Here are **all images** included in the repo, with the correct interpretation.

---

## ğŸ“Œ 1. Input Modalities (FLAIR, T1, T1CE, T2)

<div align="center">
<img src="samples/modalities.png" width="750">
</div>

---

## ğŸ“Œ 2. Mask Overlay Visualizations

### **Ground Truth Overlay**
<div align="center">
<img src="samples/overlay_groundtruth.png" width="650">
</div>

### **Prediction Overlay**
<div align="center">
<img src="samples/overlay_prediction.png" width="650">
</div>


---

## ğŸ“Œ 3. Multi-slice Segmentation Comparisons

### Version 1
<div align="center">
<img src="samples/multi_slice_segmentation_comparison.png" width="800">
</div>

### Version 2
<div align="center">
<img src="samples/multi_slice_segmentation_comparison2.png" width="800">
</div>

---

## ğŸ“Œ 4. Comparison Grid 

<div align="center">
<img src="samples/comparison_grid.png" width="700">
</div>

---

# ğŸ§± Model Architecture â€” 3D U-Net

Implemented in `src/model/Unet-3d.py`.

- 4 encoder levels  
- 4 decoder levels  
- 3D convolutions  
- Skip connections  
- Final 4-class voxel-wise prediction  

---

# ğŸ‹ï¸ Training Details

- **Dataset:** 100 patients  
- **Batch Size:** Effective 4 (using gradient accumulation Ã—4)  
- **Optimizer:** AdamW  
- **Loss:** Dice + CrossEntropy  
- **AMP:** Enabled  
- **Epochs:** 10 (baseline)  

---

# ğŸ“Š Results (100-patient baseline)

| Metric | Score |
|--------|--------|
| **Dice Class 0** | 0.99 |
| **Dice Class 1** | 0.57 |
| **Dice Class 2** | 0.79 |
| **Dice Class 3** | 0.85 |
| **Whole Tumor (WT)** | **0.86** |
| **Tumor Core (TC)** | **0.86** |
| **Enhancing Tumor (ET)** | **0.85** |

For only **100 patients**, these are strong starting results.

---

# ğŸ”® Future Work (Planned)

These upgrades will significantly boost performance:

### ğŸš€ Model Improvements
- Residual 3D U-Net  
- Attention U-Net  
- DenseNet-UNet hybrid  
- 64Ã—128Ã—128 patch-based training  

### ğŸš€ Data Improvements
- Full dataset: **1251 patients**  
- Advanced 3D augmentations (elastic, gamma, noise)  
- 160Ã—192Ã—128 resolution training  


---

# ğŸ‘¤ Author â€” **Rassem Bali**

AI Engineer â€¢ Deep Learning â€¢ Computer Vision â€¢ Medical Imaging  
ğŸ‡¹ğŸ‡³ Tunisia â€¢ ENET'Com

ğŸ”— LinkedIn: https://linkedin.com/in/rassem-bali  
ğŸ”— GitHub: https://github.com/Rassembali  

---

<div align="center">

âœ¨ *If this work helps you, please consider starring the repository!* âœ¨

</div>

